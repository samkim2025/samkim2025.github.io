<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS180 Portfolio - Project 1</title>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #34495e;
            --accent-color: #3498db;
            --text-color: #2c3e50;
            --bg-color: #f5f6fa;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            margin: 0;
            padding: 40px;
            max-width: 1200px;
            margin: 0 auto;
            background-color: var(--bg-color);
            color: var(--text-color);
        }

        h1 {
            color: var(--primary-color);
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 1.5em;
            border-bottom: 3px solid var(--accent-color);
            padding-bottom: 0.5em;
        }

        h2 {
            color: var(--secondary-color);
            margin-top: 2em;
            font-size: 1.8em;
            border-left: 4px solid var(--accent-color);
            padding-left: 15px;
        }

        .image-container {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 40px;
            transition: transform 0.3s ease;
        }

        .image-container:hover {
            transform: translateY(-5px);
        }

        .image-container h3 {
            color: var(--secondary-color);
            margin-top: 0;
            border-bottom: 2px solid var(--accent-color);
            padding-bottom: 10px;
        }

        img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            display: block;
            margin: 0 auto;
        }

        p {
            text-align: justify;
            margin-bottom: 1.5em;
        }

        .channel-info {
            background-color: #edf2f7;
            padding: 10px;
            border-radius: 5px;
            margin-top: 15px;
            font-family: monospace;
        }

        @media (max-width: 768px) {
            body {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.5em;
            }

            .image-container {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <h1>CS180 Fun with Filters and Frequencies! </h1>

    <h2>Overview</h2>

    <h2>1.1 Finite Difference Operator</h2>
    
    <p>In this part of the project, I used finite difference operators to compute the partial derivatives of the "cameraman" image (shown below) in the x and y directions.</p>
    <p>These derivatives help understand how pixel values change along these axes, which is critical for edge detection.</p>
    <div class="image-container">
        <h3>Original Cameraman</h3>
        <img src="media/Original Image.png" alt="Cameraman">
    </div>

    <div class="image-container">
        <h3>Ix</h3>
        <p>Applying the finite difference operator [-1, 1] along the x axis allows us to compute the derivative in x to highlight vertical edges.</p>
        <img src="media/Ix (Derivative in x).png" alt="Ix Cameraman">
    </div>

     <div class="image-container">
        <h3>Iy</h3>
        <p>Similarly, I applied the finite difference operator along the y axis to compute the derivative in y to highlight horizontal edges.</p>
        <img src="media/Iy (Derivative in y).png" alt="Iy Cameraman">
    </div>

    <div class="image-container">
        <h3>Gradient Magnitude</h3>
        <p>Next, I calculated the gradient magnitude, which combines the x and y derivatives to detect the overall strength of edges in the image.</p>
        <p>More specifically, I used this line of code to calculate the gradient magnitude: """ gradient_magnitude = np.sqrt(Ix**2 + Iy**2) """</p>
        <img src="media/Gradient Magnitude.png" alt="Gradient Magnitude">
    </div>

    <div class="image-container">
        <h3>Binarized Magnitude</h3>
        <p>Finally, I found an optimal threshold value based on trial and error to create a binary image that highlights the prominent edges in the image while suppressing noise.</p>
        <img src="media/Binarized Magnitude.png" alt="Binarized Magnitude">
    </div>
    

    <h2>1.2 Derivative of Gaussian (DoG) Filter</h2>

    <p>In this part of the project, I incorporated a Gaussian filter to improve upon the simple finite difference operator. While the finite difference method is effective at detecting edges, it also may produce a lot of noise. A Gaussian filter helps smooth the image before applying derivative operations.</p>
    
    <div class="image-container">
        <h3>Gaussian Filter Applied</h3>
        <p>First, I applied a Gaussian filter to the original image, which blurs the image. This also reduces noise and makes the edges more distinct. I achieved this sign the gaussian_filter() function.</p>
        <img src="media/Blurred Image.png" alt="Gaussian Applied">
    </div>

    <div class="image-container">
        <h3>Ix and Iy derivatives of the Smoothed Image</h3>
        <p>I then computed the x and y derivatives (Ix and Iy) on the smoothed image by convolving it with the finite difference operators (Dx and Dy). This gives us smoother gradients compared to the unblurred image.</p>
        <h3>Ix Blurred</h3>
        <img src="media/Ix (Blurred).png" alt="Blurred derivative of x">
        <h3>Iy Blurred</h3>
        <img src="media/Iy (Blurred).png" alt="Blurred derivative of y">
        <h3>Gradient Magnitude Double Convolved</h3>
        <img src="media/Gradient Magnitude 2.png" alt="Gradient Magnitude Double Convolution">
        <h3>Binarized Magnitude Double Convolved</h3>
        <img src="media/Binarized Magnitude 2.png" alt="Binarized Magnitude Double Convolution">
    </div>
    
    <div class="image-container">
        <h3>Gaussian Filters</h3>
        <p>Instead of applying Gaussian smoothing followed by the derivative separately, we can combine both operations into a single convolution. We can do this by computing the Derivative of Gaussian filters.</p>
        <h3>DoGx Filter</h3>
        <img src="media/DoGx filter.png" alt="DoGx Filter">
        <h3>DoGy Filter</h3>
        <img src="media/DoGy filter.png" alt="DoGy Filter">
    </div>

    <div class="image-container">
        <h3>DoG Results</h3>
        <p>I convolved the Gaussian filter with the finite difference operators (Dx and Dy) to produce DoG filters. These filters are then directly applied to the image to compute the x and y derivatives in one single step.</p>
        <h3>Ix DoG</h3>
        <img src="media/Ix (DoG).png" alt="Ix DoG">
        <h3>Iy DoG</h3>
        <img src="media/Iy (DoG).png" alt="Iy DoG">
        <h3>Gradient Magnitude DoG</h3>
        <img src="media/Gradient Magnitude (DoG).png" alt="Gradient Magnitude DoG">
        <h3>Binarized Magnitude DoG</h3>
        <img src="media/Binarized Magnitude (DoG).png" alt="Binarized Magnitude DoG">
    </div>

    <h2>2.1 Fun with Frequencies</h2>

    <p>In this part of the project, I implemented unsharp masking, which enhances the sharpness of an image by emphasizing its high-frequency components.</p>
    <p>This process has three steps: </p>
    <p>1. Gaussian Blur: First, apply a Gaussian blur, which acts as a low-pass filter that removes the high-frequency details, which are typically associated with sharp edges.</p>
    <p>2. Extracting High Frequencies: Next, I subtract the blurred version of the image from the original image, which essentially isolates the high-frequency components.</p>
    <p>3. Enhancing the Sharpness: I then added the high-frequency components back to the original image, with an adjustable weight (alpha) that controls how much the image is sharpened. This result appears sharper because the high-frequency details are emphasized.</p>

    <p>The unsharp mask filter can be mathematically represented as:</p>
    <p>Sharpened image = Original Image + alpha * (Original image - Blurred image)</p>

    <p>The following images illustrate the process mentioned above:</p>
    
    <div class="image-container">
        <h3>Original Taj Mahal</h3>
        <img src="media/Original Taj.png" alt="Original Taj">
        <h3>Sharpened Taj Mahal</h3>
        <img src="media/Sharpened Taj.png" alt="Sharpened Taj">
    </div>

    <div class="image-container">
        <h3>Original Abbey Road</h3>
        <img src="media/Original Abbey Road.png" alt="Original Abbey Road">
        <h3>Sharpened Abbey Road</h3>
        <img src="media/Sharpened Abbey Road.png" alt="Sharpened Abbey Road">
    </div>

    <div class="image-container">
        <h3>Original Free Speech</h3>
        <img src="media/Original Free Speech.png" alt="Original Free Speech">
        <h3>Sharpened Abbey Road</h3>
        <img src="media/Sharpened Free Speech.png" alt="Sharpened Free Speech">
    </div>

    <p>I also tested a scenario in which a sharp image is intentionally blurred, and then sharpened again. By comparing the original sharpened image and the sharpened version of the blurred image, we can see how much of the original detail was restored through the unsharp masking process.</p>

    <div class="image-container">
        <h3>Original MLK</h3>
        <img src="media/Original Sharp Image (MLK).png" alt="Original MLK">
        <h3>Blurred MLK</h3>
        <img src="media/Blurred MLK.png" alt="Blurred MLK">
        <h3>Sharpened MLK</h3>
        <img src="media/Sharpened Blurred Image.png" alt="Re-sharpened MLK">
    </div>

    <h2>2.2 Fun with Frequencies</h2>
    <p>In this section, I explored hybrid images, which involve combining two images in a way that allows different interpretations depending on the viewing distance.</p>
    <p>Essentially, high-frequency details dominate perception when viewed up close, while low-frequency components are more prominent from a distance.</p>
    <h3>1. Low/High Pass Filter</h3>
    <p>To create a hybrid image, I first applied a low-pass filter (Gaussian filter) to one image to isolate the low-frequency content. Next, I applied a high-pass filter to the second image by subtracting a blurred version of the image from the original, leaving only the high-frequency details. The two filtered images were then combined to form the hybrid image.</p>
    <div class="image-container">
        <h3>Original Images</h3>
        <p>These are the images I started with:</p>
        <img src="media/DerekPicture.jpg" alt="Derek"> <img src="media/nutmeg.jpg" alt="Nutmeg">
    </div>
    <h3>2. Alignment and Scaling</h3>
    <p>To align and scale the images, I manually selected points in both images to align key features and scaled them appropriately so that the high-frequency and low-frequency parts would blend smoothly.</p>
    <div class="image-container">
        <h3>3. Results</h3>
        <p>This is the image I got:</p>
        <img src="media/dereg.png" alt="Derek + Nutmeg">
    </div>
    <h3>4. Fourier Analysis:</h3>
    <p>To visualize how the frequency components are distributed in the original and hybrid images, I computed the 2D Fourier transforms of the images. This analysis shows the distribution of high and low-frequency content.</p>
    <div class="image-container">
        <p>These are the Fourier Analysis</p>
        <img src="media/fourier_derek.png" alt="Fourier Derek"> <img src="media/fourier_nutmeg.png" alt="Fourier Nutmeg"> <img src="media/fourier_hybrid.png" alt="Fourier Hybrid">
    </div>

    <h3>Other examples</h3>
    <p>These are some other images I tested the same algorithm on:</p>
    <h3>Shrek + Fiona</h3>
    <div class="image-container">
        <img src="media/shrek.jpg" alt="Shrek"> <img src="media/fiona.jpg" alt="Fiona"> <img src="media/shrekona.png" alt="Shrek + Fiona">
    </div>
    <h3>Michael Jackson</h3>
    <div class="image-container">
        <img src="media/mjblack.png" alt="MJ Young"> <img src="media/mjwhite.png" alt="MJ Old"> <img src="media/mjhybrid.png" alt="Hybrid MJ">
    </div>
    

    <h2>2.3 Gaussian and Laplacian Stacks</h2>
    <p>In this part of the project, I explored multi-resolution blending to combine two images. The goal of this technique is to combine two images seamlessly by creating a spline between the two images at various frequency levels.</p>
    <p>This technique ensures that blending appears smooth, as it processes the images at different resolutions, minimizing any harsh seams or abrupt transitions.</p>
    <p>This blending is done using two important tools: 1. Gaussian Stack  2. Laplacian Stack.</p>
    <h3>1. Gaussian Stack</h3>
    <p>A Gaussian Stack is a stack of images created by successively applying a Gaussian blur, which smooths the image at increasing levels of blurring. This stack reqpresents the low-frequency information at each level.</p>
    <div class="image-container">
        <h3>Gaussian Stack</h3>
        <p>Each level in the stack applies a Gaussian filter with increasing sigma (blur strength), but unlike a pyramid, the image size remains constant without downsampling. This stack helps represent the low-frequency components at different scales.</p>
        <h3>Apples</h3>
        <img src="media/Apple Gaussian Stack_Level_0.png" alt="Apple Gaussian Level 0"> <img src="media/Apple Gaussian Stack_Level_1.png" alt="Apple Gaussian Level 1"> <img src="media/Apple Gaussian Stack_Level_2.png" alt="Apple Gaussian Level 2"> <img src="media/Apple Gaussian Stack_Level_3.png" alt="Apple Gaussian Level 3"> <img src="media/Apple Gaussian Stack_Level_4.png" alt="Apple Gaussian Level 4">
        <h3>Orange</h3>
        <img src="media/Orange Gaussian Stack_Level_0.png" alt="Orange Gaussian Level 0"> <img src="media/Orange Gaussian Stack_Level_1.png" alt="Orange Gaussian Level 1"> <img src="media/Orange Gaussian Stack_Level_2.png" alt="Orange Gaussian Level 2"> <img src="media/Orange Gaussian Stack_Level_3.png" alt="Orange Gaussian Level 3"> <img src="media/Orange Gaussian Stack_Level_4.png" alt="Orange Gaussian Level 4">
    </div>
    
    <h3>2. Laplacian Stack</h3>
    <p>A Laplacian Stack is derived from the Gaussian stack by subtracting the next, more blurred image from the current one. It captures the high-frequency details between each level, which is crucial for multi-resolution blending.</p>
    <div class="image-container">
        <h3>Laplacian Stack</h3>
        <p>Once the Gaussian stack is built, I omcomputed the Laplacian Stack by subtracting the adjacent levels in the Gaussian stack. This stack highlights the details or high-frequency information at each level. The final Laplaian stack can then be used for image blending by merging the Laplacian stacks of two images while maintaining fine details and smooth transitions.</p>
        <h3>Apples</h3>
        <img src="media/Apple Laplacian Stack_Level_0.png" alt="Apple Laplacian Level 0"> <img src="media/Apple Laplacian Stack_Level_1.png" alt="Apple Laplacian Level 1"> <img src="media/Apple Laplacian Stack_Level_2.png" alt="Apple Laplacian Level 2"> <img src="media/Apple Laplacian Stack_Level_3.png" alt="Apple Laplacian Level 3"> <img src="media/Apple Laplacian Stack_Level_4.png" alt="Apple Laplacian Level 4">
        <h3>Orange</h3>
        <img src="media/Orange Laplacian Stack_Level_0.png" alt="Orange Laplacian Level 0"> <img src="media/Orange Laplacian Stack_Level_1.png" alt="Orange Laplacian Level 1"> <img src="media/Orange Laplacian Stack_Level_2.png" alt="Orange Laplacian Level 2"> <img src="media/Orange Laplacian Stack_Level_3.png" alt="Orange Laplacian Level 3"> <img src="media/Orange Laplacian Stack_Level_4.png" alt="Orange Laplacian Level 4">
    </div>

    <h3>The "Orapple"</h3>
    <p>With the stacks, we blend the two images. First, I resized both images to match dimensions. Next, I generated the Gaussian stack for each image to capture their low frequency content. From there, I computed the Laplacian stack to isolate the high-frequency details at each level. These stacks allow me to blend the two images smoothly, creating the famous "Orapple".</p>

    <h2>2.4 Fun with Frequencies</h2>
    <p>In this section, I focused on blending two images together using multiresolution blending. This technique allows us to seamlessly merge two images, such as the classic apple and orange images, to create what is famously known as the "Oraple".</p>
    <h3>The "Orapple"</h3>
    <p>With the stacks I created in section 2.3, we blend the two images. First, I resized both images to match dimensions. Next, I generated the Gaussian stack for each image to capture their low frequency content. From there, I computed the Laplacian stack to isolate the high-frequency details at each level. These stacks allow me to blend the two images smoothly, creating the famous "Orapple".</p>
    <img src="media/orapple.png" alt="Orapple">

    <h3>Stankeley</h3>
    <p>Using the same principle, I tried making my own set of blends -- the first being Stankeley.</p>
    <img src="media/Original Stanford Image.png" alt="Stanford">
    <img src="media/glade.jpg" alt="Glade">
    <img src="media/mask.png" alt="Custom Mask">
    <img src="media/stankeley.png" alt="Stankeley">

    <h3>Magream</h3>
    <p>Then, I sought to combine Magritte's "The Son of Man" and Munch's "The Scream".</p>
    <img src="media/magritte.jpg" alt="The Son of Man">
    <img src="media/scream.jpg" alt="The Scream">
    <img src="media/magream.png" alt="Magream">

    <h3>Failed Example</h3>
    <p>This is a failed example that was a result of changing the threshold improperly. "The Scream" isn't as prominent as the successful example above.</p>
    <img src="media/magream.jpg" alt="Magream Failed">
        
</body>
</html>
